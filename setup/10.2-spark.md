# 实训2. 在spark-shell中执行词频统计
## 2.1 编辑输入文件
本次实验统计某个文件中单词出现的次数，首先编辑输入文件。实训环境中已经提供了输入文件，路径为/root/input.txt，读者可根据需要自行编辑。文件的内容为：
> hello world hello spark hello hadoop

## 2.2 启动spark-shell
执行以下命令启动spark-shell
```
# cd /opt/spark/dist
# ./bin/spark-shell
scala>
```
## 2.3 加载本地文件
在开始具体词频统计代码之前，需要解决一个问题，就是如何加载文件？

要注意，文件可能位于本地文件系统中，也有可能存放在分布式文件系统HDFS中，本次实验只介绍如何加载本地文件，如何加载HDFS中的文件由读者探索。

然后输入下面命令加载文件：
```
scala> val textFile = sc.textFile("file:///root/input.txt")
```
上面代码中，val后面的是变量textFile，而sc.textFile()中的这个textFile是sc的一个方法名称，这个方法用来加载文件数据。这两个textFile不是一个东西，不要混淆。实际上，val后面的是变量textFile，你完全可以换个变量名称，比如,val lines = sc.textFile(“file:///root/input.txt”)。这里使用相同名称，就是有意强调二者的区别。

注意，要加载本地文件，必须采用“file:///”开头的这种格式。执行上上面这条命令以后，并不会马上显示结果，因为，Spark采用惰性机制，只有遇到“行动”类型的操作，才会从头到尾执行所有操作。所以，下面我们执行一条“行动”类型的语句，就可以看到结果：
```
scala> textFile.first()
```
first()是一个“行动”（Action）类型的操作，会启动真正的计算过程，从文件中加载数据到变量textFile中，并取出第一行文本。屏幕上会显示word.txt文件中的第一行的内容。

正因为Spark采用了惰性机制，在执行转换操作的时候，即使我们输入了错误的语句，spark-shell也不会马上报错，而是等到执行“行动”类型的语句时启动真正的计算，那个时候“转换”操作语句中的错误就会显示出来。

## 2.4 词频统计
完整代码如下：
```
scala> val textFile = sc.textFile("file:///root/input.txt")
scala> val wordCount = textFile.flatMap(line => line.split(" ")).map(word => (word, 1)).reduceByKey((a, b) => a + b)
scala> wordCount.collect()
```
上面只给出了代码，省略了执行过程中返回的结果信息，因为返回信息很多。下面简单解释一下上面的语句。

textFile包含了多行文本内容，textFile.flatMap(line => line.split(” “))会遍历textFile中的每行文本内容，当遍历到其中一行文本内容时，会把文本内容赋值给变量line，并执行Lamda表达式line => line.split(” “)。line => line.split(” “)是一个Lamda表达式，左边表示输入参数，右边表示函数里面执行的处理逻辑，这里执行line.split(” “)，也就是针对line中的一行文本内容，采用空格作为分隔符进行单词切分，从一行文本切分得到很多个单词构成的单词集合。这样，对于textFile中的每行文本，都会使用Lamda表达式得到一个单词集合，最终，多行文本，就得到多个单词集合。textFile.flatMap()操作就把这多个单词集合“拍扁”得到一个大的单词集合。

然后，针对这个大的单词集合，执行map()操作，也就是map(word => (word, 1))，这个map操作会遍历这个集合中的每个单词，当遍历到其中一个单词时，就把当前这个单词赋值给变量word，并执行Lamda表达式word => (word, 1)，这个Lamda表达式的含义是，word作为函数的输入参数，然后，执行函数处理逻辑，这里会执行(word, 1)，也就是针对输入的word，构建得到一个tuple，形式为(word,1)，key是word，value是1（表示该单词出现1次）。

程序执行到这里，已经得到一个RDD，这个RDD的每个元素是(key,value)形式的tuple。最后，针对这个RDD，执行reduceByKey((a, b) => a + b)操作，这个操作会把所有RDD元素按照key进行分组，然后使用给定的函数（这里就是Lamda表达式：(a, b) => a + b），对具有相同的key的多个value进行reduce操作，返回reduce后的(key,value)，比如(“hello”,1)和(“hello”,1)，具有相同的key，进行reduce以后就得到(“hello”,2)，这样就计算得到了这个单词的词频。